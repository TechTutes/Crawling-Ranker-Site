{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ranker.com/list/film-actors-from-india/reference?page=350\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "#initialize empty dictionary for storing Actors data\n",
    "data_dictionary = {}\n",
    "\n",
    "# coding for Crowling a web site\n",
    "\n",
    "# Url of Ranker Watch Worthy Site \n",
    "url = \"https://www.ranker.com/list/film-actors-from-india/reference\"\n",
    "\n",
    "\n",
    "#A while loop which itters until it reaches the last page of the site\n",
    "while True:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    # save the response from the site got using request library in a response library\n",
    "    response = requests.get(url)\n",
    "   \n",
    "    # save the text in data variable\n",
    "    data = response.text\n",
    "    \n",
    "    # convert the text to a soup object\n",
    "    soup = BeautifulSoup(data,'html.parser')\n",
    "    \n",
    "    # Find the block of content in our case it is a dic with class listItem__h2--grid\n",
    "    main_block = soup.find_all('div',{'class':'listItem__h2--grid'})\n",
    "    \n",
    "    # itter through every block and extract data\n",
    "    # note: this block has some celebraties names not written in a tag so we would other options to go to their profile page\n",
    "    \n",
    "    for content in main_block:\n",
    "        sub_block  = content.find('a',{'class':'listItem__title'})\n",
    "        \n",
    "    # As some actors names are in span tag we would check for both of them to get the name\n",
    "        actor_names = sub_block.text if sub_block else content.find('span',{'class':'listItem__title'}).text\n",
    "    \n",
    "    # Finding their ranker profile to get their wiki profile\n",
    "        actor_profile = content.find('span',{'class':'listItem__wiki'})\n",
    "        actor_profile_link = actor_profile.find('a')\n",
    "        \n",
    "        ranker_link = actor_profile_link.get('href') if actor_profile_link else content.find('a').get('href')  if content.find('a') else \"N/A\"\n",
    "        \n",
    "        \n",
    "        ActorName = actor_names\n",
    "        #print(ActorName)\n",
    "   \n",
    "    # go into their ranker profile\n",
    "        if(actor_profile_link):\n",
    "            a_url = 'https:'+ranker_link\n",
    "            a_response = requests.get(a_url)\n",
    "            a_data = a_response.text\n",
    "            a_soup = BeautifulSoup(a_data,'html.parser')\n",
    "            \n",
    "            #finding wiki link\n",
    "            a_block = a_soup.find('p',{'id':'node__bioWikiText'})\n",
    "            a_link = a_block.find('a')\n",
    "            w_link = a_link.get('href') if a_link else \"N/A\"\n",
    "            wikipedia_link = w_link\n",
    "            \n",
    "            \n",
    "            a_leftbox = a_soup.find('div',{'class':'node__leftRail'})\n",
    "            \n",
    "            #finding picture\n",
    "            image = a_leftbox.find('img')\n",
    "            image_src = image.get('src') if image else 'N\\A'\n",
    "            Picture = image_src\n",
    "            \n",
    "            #initialize all data to null\n",
    "            Nationality=\"N\\A\"\n",
    "            Height =\"N\\A\" \n",
    "            Age =\"N\\A\"\n",
    "            Profession =\"N\\A\"\n",
    "            Nominated = \"N\\A\"\n",
    "            Parents = \"N\\A\"\n",
    "            Children = \"N\\A\"\n",
    "            \n",
    "            #finding data\n",
    "            properties = a_leftbox.find_all('div',{'class':'node__propertiesSection'})\n",
    "            for prop in properties:\n",
    "                \n",
    "                if(prop.find('div',{'class':'node__propertiesTitle'}).text == 'Nationality'):\n",
    "                    Nationality = prop.text\n",
    "                \n",
    "                elif(prop.find('div',{'class':'node__propertiesTitle'}).text == 'Height'):\n",
    "                    Height = prop.text\n",
    "                \n",
    "                    \n",
    "                elif(prop.find('div',{'class':'node__propertiesTitle'}).text == 'Age'):\n",
    "                    Age = prop.text\n",
    "                \n",
    "                elif(prop.find('div',{'class':'node__propertiesTitle'}).text == 'Profession'):\n",
    "                    Profession = prop.text\n",
    "                \n",
    "                elif(prop.find('div',{'class':'node__propertiesTitle'}).text == 'Nominated For'):\n",
    "                    Nominated = prop.text\n",
    "                \n",
    "                elif(prop.find('div',{'class':'node__propertiesTitle'}).text == 'Parents'):\n",
    "                    Parents = prop.text\n",
    "               \n",
    "                elif(prop.find('div',{'class':'node__propertiesTitle'}).text == 'Children'):\n",
    "                    Children = prop.text\n",
    "                    \n",
    "          # if  wiki link  is not found we set the variables to null      \n",
    "        else:\n",
    "            wikipedia_link = \"N\\A\"\n",
    "            Picture =\"N\\A\"\n",
    "            Nationality=\"N\\A\"\n",
    "            Height =\"N\\A\" \n",
    "            Age =\"N\\A\"\n",
    "            Profession =\"N\\A\"\n",
    "            Nominated = \"N\\A\"\n",
    "            Parents = \"N\\A\"\n",
    "            Children = \"N\\A\"\n",
    "\n",
    "\n",
    "\n",
    "    # update the dictionary\n",
    "        data_dictionary[ActorName] = [Profession, Height, Age, Profession, Nominated, Parents, Children, Picture, wikipedia_link ]\n",
    "        \n",
    "   # Link to more pages     \n",
    "    url_tag = soup.find('a',{'id':'pagination'})\n",
    "    \n",
    "    # next page link\n",
    "    if url_tag.get('href'):\n",
    "        url= 'https:' + url_tag.get('href')\n",
    "    # if its the last page\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    # as this site dont have any last page and go on increasing with empty pa we stop the block when the main block is empty \n",
    "    if (main_block == []):\n",
    "        break\n",
    "        \n",
    "    # crowling part end\n",
    "    \n",
    "# Creating a dataset\n",
    "Actors_df = pd.DataFrame.from_dict(data_dictionary, orient = 'index', columns = ['Profession','Height','Age', 'Profession', 'Nominated', 'Parents','Children','Picture','wikipedia_link'])\n",
    "    \n",
    "# Exporting to csv\n",
    "Actors_df.to_csv('Actors_info.csv')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
